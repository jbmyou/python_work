{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # md5 : 속도보다 보안 but 보안도 이제는 떨어진다지만\n",
    "# 테스트해보니 속도, 결과 crc32랑 차이없네?!\n",
    "# import hashlib\n",
    "# def md5(file1):\n",
    "#     md5h = hashlib.md5()\n",
    "#     with open(file1, \"rb\") as f:\n",
    "#         for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "#             md5h.update(chunk)\n",
    "#     return md5h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import re\n",
    "import binascii # 내장모듈\n",
    "import pickle # 내장모듈\n",
    "from os.path import join\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileNameScore(filename:str) -> int :\n",
    "    \"\"\"파일명에서 특정 항목이 있는지 추리는 함수\n",
    "    채무자키 있음 : 10만\n",
    "    대체키 있음 : 1만\n",
    "    사건번호 있음 : 1000\n",
    "    문서구분 있음 : 100\n",
    "    길이 : stem 길이\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    f = filename\n",
    "    # compile\n",
    "    \n",
    "    # 채무자키 match\n",
    "    p_key = re.compile(r\"[\\d]{8}(?!\\d)\") \n",
    "    # 사업자/주민번호/관리자키\n",
    "    p_extraKey = re.compile(r'([\\d]{3})-\\d\\d-\\d\\d\\d\\d\\d[\\D]+|([\\d]{6})-([\\d]{6})[\\D]+|[\\d]{10}[\\D]|[\\D][\\d]{4}-[\\d]{6}[\\D]')\n",
    "    # 사건번호\n",
    "    p_event1=re.compile(r\"((?<=\\D)|^)(19\\d\\d|20[012]\\d)\\s?(준?재?[가나느차카타즈본징하개회][가-힣]?)\\s?([0-9]+)\")\n",
    "    p_event2=re.compile(r\"((?<=\\D)|^)([012]\\d)\\s?(준?재?[가나느차카타즈본징하개회][가-힣]?)\\s?([0-9]+)\")\n",
    "    # 문서구분\n",
    "    p_docu = re.compile(r'원인|양도통지서|양통|종적|승계|집행|판결|명령|이행|화해|재도|재부여|압류|압추|추심|유체|동산|배당|타채|결정|(등|초)본|외국인|개회|신복|파산|내용|신용|등기|부채|재산|대장')\n",
    "    \n",
    "    if p_key.match(f) : score += 100000 # 날짜같은것과 구분짓기 위해 match필수\n",
    "    else :\n",
    "        if p_extraKey.search(f) : score += 10000 # 채무자키 없을 때만, 채무자키 있으면 쓸모없는 정보이므로 점수 x\n",
    "    if p_event1.search(f) or p_event2.search(f) : score += 1000\n",
    "    if p_docu.search(f) : score += 100\n",
    "\n",
    "    real_f = f\n",
    "    real_f = p_key.sub(\"\", real_f)\n",
    "    real_f = p_extraKey.sub(\"\", real_f)\n",
    "    real_f = p_event1.sub(\"\", real_f)\n",
    "    real_f = p_event2.sub(\"\", real_f)\n",
    "    real_f = p_docu.sub(\"\", real_f)\n",
    "    score += len(os.path.splitext(real_f)[0]) # score에 선반영 된 것들 제외한 파일명 길이 점수\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crc32_checksum(filename):\n",
    "    buf = open(filename,'rb').read()\n",
    "    buf = (binascii.crc32(buf) & 0xFFFFFFFF)\n",
    "    return \"%08X\" % buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_info(path:str,savePath = \"./파일/중복조사\"):\n",
    "    \"\"\"\n",
    "    하위경로포함 모든 파일에 대해 size,cre32로 중복 검사 후 \n",
    "    모든 파일 정보 및 중복파일 목록을 excel, pickle로 파일폴더에 저장\n",
    "    path : 중복검사할 최상위 디렉토리\n",
    "    savePath : 검사 결과 파일을 저장할 디렉토리\n",
    "    \"\"\"\n",
    "    savePath = savePath\n",
    "    dict_sc = {}  #중복파일끼리 묶을 딕셔너리(size+cre)\n",
    "    df = None\n",
    "    data = []\n",
    "    p_extension = re.compile('jpeg|jpg|bmp|gif|pdf|png|tif|tiff|m4a|wav|mp[34]|xps$', re.I)\n",
    "    df_matching = pd.read_excel('./파일/매각사 이름매칭.xlsx')\n",
    "\n",
    "    for root, __dirs__, files in tqdm(os.walk(path)):\n",
    "        for f in files:\n",
    "            if (p_extension.search(f)!=None) and (re.match(\"[~$]\", f) == None) :\n",
    "                fullPath = join(root, f)\n",
    "                #key\n",
    "                size = str(os.path.getsize(fullPath))\n",
    "                #value\n",
    "                mtime = str(os.path.getmtime(fullPath))\n",
    "                crc32 = str(crc32_checksum(fullPath))\n",
    "                sell = \"매각사\" # 검색결과가 없을 수 있으니\n",
    "                for __index__, row in df_matching.iterrows():\n",
    "                    if re.search(str(row[0]), str(root)):  \n",
    "                        sell = row[1]\n",
    "                        break            \n",
    "                stem = os.path.splitext(f)[0]\n",
    "                ext = os.path.splitext(f)[1]\n",
    "                \n",
    "                score = fileNameScore(f) ##\n",
    "                sc = size + crc32\n",
    "\n",
    "                temp = {\"sc\":sc, \"score\" : score, \"root\" : root, \"stem\":stem, \"ext\":ext, \"fullPath\" : fullPath, \"size\":size, \"crc32\": crc32, \"mtime\":mtime, \"sell\":sell}\n",
    "                data.append(temp)\n",
    "                \n",
    "                # 고유한 size, crc를 키로 하는 2중 딕셔너리 만들기\n",
    "                if sc not in dict_sc:\n",
    "                    dict_sc[sc] = [temp]\n",
    "                else:\n",
    "                    dict_sc[sc].append(temp)\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(data)\n",
    "    sc_dupl = df.duplicated(['size', 'crc32'], keep=False) # 중복파일은 모두 마크하기(series)\n",
    "    sc_dupl.name = \"sc_dupl\" # 칼럼이름\n",
    "    df = pd.concat([df, sc_dupl], axis=1) # 새로운 열로 결합하기\n",
    "    #df_sc_dupl = df[df[\"sc_dupl\"]] # dupl인 것만 새로운 df에 담기 return용\n",
    "    \n",
    "    #add_dir = path.split(\"\\\\\")[-1]\n",
    "    # if not os.path.exists(join(savePath,add_dir)):\n",
    "    #     os.mkdir(join(savePath,add_dir))\n",
    "    \n",
    "    # 파일 내보내기1 : path내 모든 파일(만일을 위해)\n",
    "    if not os.path.exists(savePath) : \n",
    "        os.makedirs(savePath)\n",
    "\n",
    "    df.to_excel(join(savePath, \"전체 파일정보.xlsx\"))\n",
    "    df.to_pickle(join(savePath,\"전체 파일정보.pkl\"))\n",
    "    total = len(df.index) \n",
    "    \n",
    "    # 파일 내보내기2 : s+c끼리 묶은 2중 dict\n",
    "    with open(join(savePath,\"sc별 파일정보.pkl\"), \"wb\") as pkl :\n",
    "        pickle.dump(dict_sc, pkl)\n",
    "\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 파일 개수 : 72362\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "path = r'D:\\1.다운로드\\__부산 공유폴더_원본' \n",
    "path_dupl = r'D:\\1.다운로드\\삭제예정파일\\중복_스캔파일'\n",
    "#####################################################\n",
    "savePath = r\"./파일/중복조사\"\n",
    "total = file_info(path)\n",
    "print(f\"전체 파일 개수 : {total}\") # 전체 파일 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 남길파일 이동파일 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68746\n"
     ]
    }
   ],
   "source": [
    "with open(\"./파일/중복조사/sc별 파일정보.pkl\", \"rb\") as pkl :\n",
    "    dict = pickle.load(pkl)\n",
    "print(len(dict)) # 파일 그룹 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total : 72362개.  key : 17664, extraKey : 50440, noKeyRemain : 642, dupl : 3616\n",
      "누수 파일 0개\n"
     ]
    }
   ],
   "source": [
    "noKeyList = []\n",
    "keyCnt, extraKeyCnt, duplCnt = 0, 0, 0\n",
    "\n",
    "for key, ListOfSubDict in tqdm(dict.items()) : # 파일 그룹 단위 반복\n",
    "#\"score\" : score, \"root\" : root, \"stem\":stem, \"ext\":ext, \"fullPath\" : fullPath, \"size\":size, \"crc32\": crc32, \"mtime\":mtime, \"sell\":sell\n",
    "    num = len(ListOfSubDict)\n",
    "    if num == 1 :\n",
    "        pass\n",
    "    else :\n",
    "        for i in range(num):\n",
    "            highscore = i\n",
    "            for j in range((i+1), num) :\n",
    "                if ListOfSubDict[i][\"score\"] < ListOfSubDict[j][\"score\"] : # 바뀌는 경우\n",
    "                    ListOfSubDict[i], ListOfSubDict[j] = ListOfSubDict[j], ListOfSubDict[i] # 딕셔너리 내부에서도 작동함.\n",
    "\n",
    "            \n",
    "    # 1. 하나의 파일 그룹에 대한 정렬이 끝났다.-----------------\n",
    "\n",
    "    # 1.1) 점수가 가장 높고, key 있는 파일 채무자키폴더로 이동\n",
    "    # root - path -1(디렉토리 구분자 제거) = subdir\n",
    "    if ListOfSubDict[0][\"score\"] >= 100000 :\n",
    "        src = ListOfSubDict[0][\"fullPath\"]\n",
    "        dst_dir = join(path, \"key\", ListOfSubDict[0][\"root\"][len(path)+1:])\n",
    "        dst = join(dst_dir, os.path.split(src)[1])\n",
    "\n",
    "        if not os.path.exists(dst_dir) :\n",
    "            os.makedirs(dst_dir)\n",
    "        shutil.move(src, dst)\n",
    "        keyCnt += 1\n",
    "\n",
    "    # 1.2) 점수가 가장 높지만, extraKey 있는 파일 extraKey폴더로 이동\n",
    "    elif ListOfSubDict[0][\"score\"] >= 10000 :\n",
    "        src = ListOfSubDict[0][\"fullPath\"]\n",
    "        dst_dir = join(path, \"extraKey\", ListOfSubDict[0][\"root\"][len(path)+1:])\n",
    "        dst = join(dst_dir, os.path.split(src)[1])\n",
    "\n",
    "        if not os.path.exists(dst_dir) :\n",
    "            os.makedirs(dst_dir)\n",
    "        shutil.move(src, dst)\n",
    "        extraKeyCnt += 1\n",
    "\n",
    "    # 점수가 가장 높지만, key가 전혀 없는 것 root, stem, ext, fullPath(\\\\192...으로 변경해야 하니까 원형 유지를 위해 root, fileName도 저장한다.)\n",
    "    # 를 df에 담아 for문 끝난 후 엑셀로 저장\n",
    "    # fullPath 하이퍼 링크 걸어주고, 편하게 파일 보면서 newName 저장\n",
    "    else :\n",
    "        noKeyList.append([ListOfSubDict[0][\"root\"], ListOfSubDict[0][\"stem\"], ListOfSubDict[0][\"ext\"], ListOfSubDict[0][\"fullPath\"]])\n",
    "\n",
    "\n",
    "    # 점수가 가장 높지 않은 것 중복파일 폴더로 이동. 파일이름 같은 거 삭제.\n",
    "    for k in range(1, num) :\n",
    "        src = ListOfSubDict[k][\"fullPath\"]\n",
    "        dst_dir = join(path_dupl, ListOfSubDict[0][\"stem\"]) # 대표파일 폴더 아래에 중복파일을 넣기 때문에 [0][stem]\n",
    "        dst = join(dst_dir, os.path.split(src)[1])\n",
    "\n",
    "        if not os.path.exists(dst_dir) :\n",
    "            os.makedirs(dst_dir)\n",
    "        shutil.move(src, dst)   \n",
    "        duplCnt += 1\n",
    "\n",
    "# 제 자리에 두는 파일 목록 엑셀로 변환\n",
    "df_noKey = pd.DataFrame(noKeyList, columns=[\"root\", \"stem\", \"ext\", \"fullPath\"])\n",
    "df_noKey.to_excel(join(savePath, \"remain.xlsx\"))\n",
    "\n",
    "actCnt = keyCnt + extraKeyCnt + len(noKeyList) + duplCnt\n",
    "print(f\"total : {total}개.  key : {keyCnt}, extraKey : {extraKeyCnt}, noKeyRemain : {len(noKeyList)}, dupl : {duplCnt}\") \n",
    "print(f\"누수 파일 {total - actCnt}개\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50ba2c93e3505a279245e213c77d9791c626788d8ca8a61b8db804927ca08a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
